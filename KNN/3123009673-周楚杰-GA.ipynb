{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dd6a46f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd = D:\\qq\\WORK1\\WORK\n",
      "Reading train/evaltask2_sample_data/cn_sample_data/sample.positive.txt...\n",
      "Loaded 5000 samples from train/evaltask2_sample_data/cn_sample_data/sample.positive.txt\n",
      "Reading train/evaltask2_sample_data/cn_sample_data/sample.negative.txt...\n",
      "Loaded 5000 samples from train/evaltask2_sample_data/cn_sample_data/sample.negative.txt\n",
      "Reading test mark/Sentiment Classification with Deep Learning/test.label.cn.txt...\n",
      "Loaded 2500 samples from test mark/Sentiment Classification with Deep Learning/test.label.cn.txt\n",
      "\n",
      "Total Training Samples: 10000\n",
      "Total Test Samples: 2500\n",
      "\n",
      "Vectorizing text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaca\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (10000, 5000)\n",
      "\n",
      "Training KNN Classifier (k=10, metric='cosine')...\n",
      "Predicting on test set...\n",
      "\n",
      "========================================\n",
      "SENTIMENT ANALYSIS REPORT\n",
      "========================================\n",
      "Accuracy: 0.6832\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.67      0.72      0.70      1250\n",
      "    Positive       0.70      0.64      0.67      1250\n",
      "\n",
      "    accuracy                           0.68      2500\n",
      "   macro avg       0.68      0.68      0.68      2500\n",
      "weighted avg       0.68      0.68      0.68      2500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[906 344]\n",
      " [448 802]]\n",
      "\n",
      "Total execution time: 6.61 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r\"D:\\qq\\WORK1\\WORK\")\n",
    "print(\"cwd =\", os.getcwd())\n",
    "import re\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import time\n",
    "\n",
    "\n",
    "REVIEW_PATTERN = re.compile(r'<review id=\"(?P<id>\\d+)\"(?:\\s+label=\"(?P<label>\\d+)\")?>(?P<text>.*?)</review>', re.DOTALL)\n",
    "\n",
    "def load_data(file_path, default_label=None):\n",
    "    texts = []\n",
    "    labels = []\n",
    "  \n",
    "    print(f\"Reading {file_path}...\")\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "    except UnicodeDecodeError:\n",
    "\n",
    "       with open(file_path, 'r', encoding='gb18030') as f:\n",
    "            content = f.read()\n",
    "\n",
    "    matches = REVIEW_PATTERN.finditer(content)\n",
    "    for match in matches:\n",
    "        text = match.group('text').strip()\n",
    "        label_str = match.group('label')\n",
    "      \n",
    "        if label_str is not None:\n",
    "            labels.append(int(label_str))\n",
    "        elif default_label is not None:\n",
    "            labels.append(default_label)\n",
    "        else:\n",
    "         \n",
    "            continue\n",
    "          \n",
    "        texts.append(text)\n",
    "      \n",
    "    print(f\"Loaded {len(texts)} samples from {file_path}\")\n",
    "    return texts, labels\n",
    "\n",
    "def tokenize(text):\n",
    "    return jieba.lcut(text)\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "  \n",
    "    # 文本\n",
    "    train_pos_path = r'train/evaltask2_sample_data/cn_sample_data/sample.positive.txt'\n",
    "    train_neg_path = r'train/evaltask2_sample_data/cn_sample_data/sample.negative.txt'\n",
    "    test_label_path = r'test mark/Sentiment Classification with Deep Learning/test.label.cn.txt'\n",
    "  \n",
    "    # 加载数据\n",
    "    pos_texts, pos_labels = load_data(train_pos_path, default_label=1)\n",
    "    neg_texts, neg_labels = load_data(train_neg_path, default_label=0)\n",
    "  \n",
    "    train_texts = pos_texts + neg_texts\n",
    "    train_labels = pos_labels + neg_labels\n",
    "  \n",
    "    #加载测试数据\n",
    "    test_texts, test_labels = load_data(test_label_path)\n",
    "  \n",
    "    print(f\"\\nTotal Training Samples: {len(train_texts)}\")\n",
    "    print(f\"Total Test Samples: {len(test_texts)}\")\n",
    "  \n",
    "    # 输出\n",
    "    print(\"\\nVectorizing text...\")\n",
    "    vectorizer = TfidfVectorizer(tokenizer=tokenize, max_features=5000) \n",
    "    X_train = vectorizer.fit_transform(train_texts)\n",
    "    X_test = vectorizer.transform(test_texts)\n",
    "  \n",
    "    print(f\"Feature matrix shape: {X_train.shape}\")\n",
    "  \n",
    "    # KNN \n",
    "    print(\"\\nTraining KNN Classifier (k=10, metric='cosine')...\")\n",
    "    knn = KNeighborsClassifier(n_neighbors=10, metric='cosine')\n",
    "    knn.fit(X_train, train_labels)\n",
    "  \n",
    "    print(\"Predicting on test set...\")\n",
    "    y_pred = knn.predict(X_test)\n",
    "  \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"SENTIMENT ANALYSIS REPORT\")\n",
    "    print(\"=\"*40)\n",
    "  \n",
    "    acc = accuracy_score(test_labels, y_pred)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "  \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(test_labels, y_pred, target_names=['Negative', 'Positive']))\n",
    "  \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(test_labels, y_pred))\n",
    "  \n",
    "    print(f\"\\nTotal execution time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a5ba708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "     ---------------------------------------- 0.0/19.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/19.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/19.2 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/19.2 MB 245.8 kB/s eta 0:01:19\n",
      "     --------------------------------------- 0.1/19.2 MB 357.2 kB/s eta 0:00:54\n",
      "     --------------------------------------- 0.1/19.2 MB 420.8 kB/s eta 0:00:46\n",
      "     --------------------------------------- 0.2/19.2 MB 654.4 kB/s eta 0:00:30\n",
      "      -------------------------------------- 0.3/19.2 MB 999.0 kB/s eta 0:00:19\n",
      "      --------------------------------------- 0.4/19.2 MB 1.2 MB/s eta 0:00:17\n",
      "     - -------------------------------------- 0.8/19.2 MB 2.0 MB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.9/19.2 MB 2.1 MB/s eta 0:00:09\n",
      "     -- ------------------------------------- 1.4/19.2 MB 2.7 MB/s eta 0:00:07\n",
      "     ---- ----------------------------------- 2.2/19.2 MB 3.9 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 2.3/19.2 MB 3.8 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 3.8/19.2 MB 5.7 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 3.8/19.2 MB 5.4 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 4.4/19.2 MB 6.2 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 5.5/19.2 MB 6.9 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 6.3/19.2 MB 7.5 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 7.3/19.2 MB 8.3 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 8.0/19.2 MB 8.6 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 9.2/19.2 MB 9.5 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 10.3/19.2 MB 11.7 MB/s eta 0:00:01\n",
      "     ---------------------- ---------------- 11.1/19.2 MB 16.0 MB/s eta 0:00:01\n",
      "     ----------------------- --------------- 11.6/19.2 MB 17.2 MB/s eta 0:00:01\n",
      "     -------------------------- ------------ 13.1/19.2 MB 19.3 MB/s eta 0:00:01\n",
      "     -------------------------- ------------ 13.1/19.2 MB 19.3 MB/s eta 0:00:01\n",
      "     -------------------------- ------------ 13.1/19.2 MB 19.3 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 13.8/19.2 MB 15.6 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 14.8/19.2 MB 17.2 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 14.9/19.2 MB 16.8 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 14.9/19.2 MB 16.8 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 14.9/19.2 MB 16.8 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 15.2/19.2 MB 13.4 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 15.2/19.2 MB 13.4 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 15.2/19.2 MB 13.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 16.5/19.2 MB 12.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 16.8/19.2 MB 11.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 17.0/19.2 MB 11.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 17.0/19.2 MB 10.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 17.3/19.2 MB 10.4 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 17.3/19.2 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 18.0/19.2 MB 9.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 18.6/19.2 MB 9.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  19.1/19.2 MB 9.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  19.2/19.2 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 19.2/19.2 MB 8.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas in d:\\anaca\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in d:\\anaca\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in d:\\anaca\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: matplotlib in d:\\anaca\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: seaborn in d:\\anaca\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaca\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaca\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\anaca\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\anaca\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\anaca\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaca\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\anaca\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaca\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaca\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaca\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaca\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\anaca\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\anaca\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaca\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Building wheels for collected packages: jieba\n",
      "  Building wheel for jieba (setup.py): started\n",
      "  Building wheel for jieba (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314474 sha256=057c7a70366c6b05a21f6a722ff97d60bbe8c274d8830df29502c47325a65839\n",
      "  Stored in directory: c:\\users\\11835\\appdata\\local\\pip\\cache\\wheels\\ac\\60\\cf\\538a1f183409caf1fc136b5d2c2dee329001ef6da2c5084bef\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "Successfully installed jieba-0.42.1\n"
     ]
    }
   ],
   "source": [
    "!pip install jieba pandas numpy scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8654cc41-3833-4bec-8d60-1a982176e9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
